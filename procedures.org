* 1.2 | Procedures and the Processes They Generate
  :PROPERTIES:
  :header-args: :session scheme :results verbatim raw
  :END:

A procedure is a pattern for the local evolution of a computational process. It specifies how each stage of the process is built upon the previous stage. We would like to be able to make statements about the overall, or global, behavior of a process whose local evolution has been specified by a procedure. 

** 1.2.1 | Linear Recursion and Iteration

#+BEGIN_SRC scheme
(define (factorial n)
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))

(factorial 5)
#+END_SRC

#+RESULTS:
120
120
3628800
1
2

This is the linear recursive method for computing factorials


#+DOWNLOADED: /tmp/screenshot.png @ 2020-02-02 10:52:25
[[file:1.2 | Procedures and the Processes They Generate/screenshot_2020-02-02_10-52-25.png]]

The substitution model reveals a shape of expansion followed by contraction. The expansion occurs as the process builds up a chain of deferred operations. The contraction occurs as the operations are actually performed. 

This type of process, characterized by a chain of deferred operations, is called a recursive process. 

#+BEGIN_SRC scheme
(define (factorial n)
  (define (iter product counter)
    (if (> counter n)
        product
        (iter (* product counter) 
              (+ counter 1))))

  (iter 1 1))

(factorial 5)
#+END_SRC

#+RESULTS:
120
1
1
720
factorial

This is the linear iterative process for computing a factorial.

#+DOWNLOADED: /tmp/screenshot.png @ 2020-02-02 10:56:28
[[file:1.2 | Procedures and the Processes They Generate/screenshot_2020-02-02_10-56-28.png]]

In contrast to the above, this method does not grow and shrink. At each step we keep track of, for any n, the current values of product, counter, and max-count. This is an iterative process. 

In general, an iterative process is one whose state can be summarized by a fixed number of state variables, together with a fixed rule that describes how the state variables should be updated as the process moves from state to state and an optional end test that specifies conditions under which the process should terminate. 

In contrasting iteration and recursion, we must not confuse the notion of a recursive process with the notion of a recursive procedure. 

When we describe a procedure as recursive, we are referrring to the syntactic fact that the procedure definition refers (either directly or indirectly) to the procedure itself.

When we describe a process as following a pattern that is linearly recursive we are speaking about how the process evolves, not about the syntax with how it is written. 

This is confusing because the implementation of most imperative languages are designed in such a way that the interpretation of any recursive procedure consumes an amount of memory that grows with the number of procedure calls. As a consequence, these languages resort to special purpose looping constructs such as do, repeat, until, for, and while. 

In contrast scheme executes an iterative process in constant space, even if the iterative process is described by a recursive procedure. An implementation with this property is called tail recursive. 

- Exercise 1.9 

#+BEGIN_SRC scheme
(define (+ a b)
  (if (= a 0)
      b
      (inc (+ (dec a) b))))
#+END_SRC

#+BEGIN_SRC scheme
(+ 4 5)
(inc (+ 3 5))
(inc 8)
(9)
#+END_SRC

#+BEGIN_SRC scheme
(+ 4 5)
(inc (+ (dec 4) 5))
(inc (+ 3 5))
(inc (inc (+ (dec 3) 5)))
(inc (inc (+ 2 5)))
(inc (inc (inc (+ (dec 2) 5))))
(inc (inc (inc (+ 1 5))))
(inc (inc (inc (inc (+ (dec 1) 5)))))
(inc (inc (inc (inc (+ 0 5)))))
(inc (inc (inc (inc 5))))
(inc (inc (inc 6)))
(inc (inc 7))
(inc 8)
9
#+END_SRC

This is a recursive process

#+BEGIN_SRC scheme
(define (+ a b)
  (if (= a 0)
      b
      (+ (dec a) (inc b))))
#+END_SRC

#+BEGIN_SRC scheme
(+ 4 5)
(+ 3 6)
(+ 2 7)
(+ 1 8)
(+ 0 9)
9
#+END_SRC

This is an iterative process

- 1.10 

#+BEGIN_SRC scheme
(define (ackermann x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (Ackermann (- x 1)
                         (Ackermann x (- y 1))))))
#+END_SRC

#+RESULTS:
ackermann
ackermann

#+BEGIN_SRC scheme
(ackermann 1 10)
#+END_SRC

#+RESULTS:
1024

#+BEGIN_SRC scheme
(ackermann 2 4)
#+END_SRC

#+RESULTS:
65536

#+BEGIN_SRC scheme
(ackermann 3 3)
#+END_SRC

#+RESULTS:
65536

#+BEGIN_SRC scheme
(define (f n) (Ackermann 0 n))
(define (g n) (Ackermann 1 n))
(define (h n) (Ackermann 2 n))
(define (k n) (* 5 n n))
#+END_SRC


- (f n) : 2n

#+BEGIN_SRC scheme
A (0, n)
2n
#+END_SRC

#+BEGIN_SRC scheme
(ackermann 0, 4)
#+END_SRC

- (g n) : 

#+BEGIN_SRC scheme
A (1, n)
A (0, A (1, n-1))
A (0, A (0, A (1, n-2)))
A (0, A (0, A (0, A (1, n - 3))))
...
until y = 1, in which case we have 
2 ( 2 ( 2 ( ... ( 2)))), or 2^n
#+END_SRC

#+BEGIN_SRC scheme
(ackermann 1 4)
#+END_SRC

#+RESULTS:
16

- (h n) : 

#+BEGIN_SRC scheme
A (2, n)
A (1, A (2, n - 1))
A (1, A (1, A (2, n - 2)))
...
A (1, A (1, ...n..., 2))
(2^n (2^n (2^n, ...n..., 2^n)))
(2^n)^n

We know A (1, n) ~ 2^n, and we know this will terminate when y = 1 with a 2. Therefore we will get one full set of A (1, ...) that consists of n terms per x, and each of these terms will become 2^n. Thus we get (2^n)^n
#+END_SRC

#+BEGIN_SRC scheme
(ackermann 2 4)
#+END_SRC

#+RESULTS:
65536

** 1.2.2 | Tree Recursion

Another common pattern of computation is called tree recursion. 

#+BEGIN_SRC scheme
(define (fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))

(fib 5)
#+END_SRC

#+RESULTS:
5
3
2
1
1
0
fib


#+DOWNLOADED: /tmp/screenshot.png @ 2020-02-03 20:37:41
[[file:1.2 | Procedures and the Processes They Generate/screenshot_2020-02-03_20-37-41.png]]

This procedure is instructive, but hopelessly inefficient. Almost half the computation is repeated twice. 

The value of Fib(n) grows exponentially with n. More precisely, Fib(n) is the closest integer to $\phi^n / \sqrt{5}$, where 

$\phi = \frac{1 + \sqrt{5}}{2} ~ 1.618$

is the golden ratio, which satisfies the equation 

$\phi^2 = \phi + 1$

Thus the process uses a number of steps that grow exponentially with the input. On the other hand, the space required grows only linearly with the input, because we need keep track of only which nodes are above us in the tree at any point in the computation. 

In general, the number of steps required by a tree-recursive process will be proportional to the number of nodes in the tree, while the space required will be proportional to the maximum depth of the tree.

We can also formulate an iterative process for computing the Fibonacci numbers, in which we use a pair of integers a and b initialized to Fib(1) and Fib(0), to repeatedly apply the transformations

$a <- a + b$
$b <- a$

#+BEGIN_SRC scheme
(define (fib n)
  (define (iter a b count)
    (if (= count 0)
        b
        (iter (+ a b) a (- count 1))))
  (iter 1 0 n))

(fib 50)
#+END_SRC

#+RESULTS:
12586269025
21
13
8
5
3
2
1
1
0
fib

This method is a linear iteration. The difference in number of steps required by the two methods is enormous, even for small inputs.

We should not conclude that tree-recursive processes are useless. When we consider processes that operate on hierarchically structured data rather than numbers, we will find that tree recursion is a natural and powerful tool.

Notice how much easier and natural the first approach was in contrast to the second approach. The first is essentially a recasting of the definition into lisp, whereas the second needed to place it in the context of using 3 state variables.

*Example: Counting Change*

How many different ways can we make change of $1.00, given half-dollars, quarters, dimes, nickels, and pennies? 

Suppose we think of the types of coins available as arranged in some order. Then the following relation holds:

The number of ways to change amount a using n kinds of coins equals

- the number of ways to change amount a using all but the first kind of coin, plus
- the number of ways to change amount a - d, using all n kinds of coins where d is the denomination of the first coin 

Observe that the ways to make change can be divided into two groups: those that do not use any of the first kind of coin and those that do. Therefore, the total number of ways to make change for some amount is equal to the number of ways to make change for the amount without using any of the first kind of coin, plus the number of ways to make change assuming that we do use the first kind of coin. But the latter number is equal to the number of ways to make change for the amount that remains after using a coin of the first kind. 

Thus we can recursively reduce the problem of changing a given amount to the problem of changing smaller amounts using fewer kinds of coins. 

- If a is exactly 0, we should count that as 1 way to make change
- If a is less than 0, we should count that as 0 ways to make change.
- If n is 0, we should count that as 0 ways to make change

#+BEGIN_SRC scheme
(define (count-change amount)
  (define (first-denomination kinds-of-coins)
    (cond ((= kinds-of-coins 1) 1)
          ((= kinds-of-coins 2) 5)
          ((= kinds-of-coins 3) 10)
          ((= kinds-of-coins 4) 25)
          ((= kinds-of-coins 5) 50)))
  
  (define (cc amount kinds-of-coins)
    (cond ((= amount 0) 1)
          ((or (< amount 0) (= kinds-of-coins 0)) 0)
          (else (+ (cc amount (- kinds-of-coins 1))
                   (cc (- amount 
                          (first-denomination
                           kinds-of-coins))
                       kinds-of-coins)))))
  (cc amount 5))
#+END_SRC

#+RESULTS:
count-change

The first-denomination procedure takes as input the number of kinds of coins available and returns the denomination of the first kind. 

#+BEGIN_SRC scheme
(count-change 100)
#+END_SRC

#+RESULTS:
292

This procedure generates a tree-recursive process with redundancies similar to our first implementation of fib. 

generate all the ways to get our amount with one coin type
this is 5 ways

generate pennies - first denom (nickels). Then we have 95 pennies, 1 nickel, 90, 2 nickels, etc for another 20 ways. 

then generate pennies - second denom (dimes). Then we have 90 pennies, 1 dime, 85 pennies, 1 nickel, 1 dime, 80 pennies, 2 nickels, 1 dime, 80 pennies, 2 dimes

#+BEGIN_SRC scheme

#+END_SRC

- Exercise 1.1121

function is defined by 


#+DOWNLOADED: /tmp/screenshot.png @ 2020-02-03 21:22:21
[[file:1.2 | Procedures and the Processes They Generate/screenshot_2020-02-03_21-22-21.png]] 

#+BEGIN_SRC scheme
(define (fun n)
  (cond ((< n 3) n)
        (else (+ (fun (- n 1))
                 (* (fun (- n 2)) 2)
                 (* (fun (- n 3)) 3)))))

(fun 8)
#+END_SRC

#+RESULTS:
335

#+BEGIN_SRC scheme
(define (fun2 n)
  (define (iter a b c count)
    (cond ((< count 0) count)
          ((= count 0) a)
          ((= count 1) b)
          ((= count 2) c)
          (else (iter b c (+ c (* 2 b) (* 3 a)) (- count 1)))))
  (iter 0 1 2 n))
#+END_SRC

#+RESULTS:
fun2

#+BEGIN_SRC scheme
(fun2 8)
#+END_SRC

Fix this ^^^ 

- Exercise 1.12 

Generate nth row and kth column of pascal's triangle

#+BEGIN_SRC scheme
(define (pascal n k)
  (cond ((= n 0) 1)
        ((= k 0) 1)
        ((/ (factorial n)
            (* (factorial k)
               (factorial (- n k)))))))
#+END_SRC

#+RESULTS:
pascal

#+BEGIN_SRC scheme
(pascal 6 3)
#+END_SRC

Generate sum of entire nth row to the kth column

** 1.2.3 | Orders of Growth

- Exercise 1.15

The sine of an angle (specified in radians) can be computed by making use of the approximation sin x ~ x if x is sufficiently small, and the trigonometric identity 

$\sin{x} = 3\sin{\frac{x}{3}} - 4\sin{\frac{x}{3}}^3$

to reduce the size of the argument of sin. For the purposes of this exercise, an angle is considered sufficiently small if its magnitude is not greater than 0.1 radians. 

#+BEGIN_SRC scheme
(define (abs x)
  (cond ((< x 0) (- x))
        (else x)))

(define (cube x) (* x x x))

(define (t-identity x)
  (- (* 3 x) (* 4 (cube x))))

(define (sine angle)
  (if (not (> (abs angle) 0.1))
      angle
      (t-identity (sine (/ angle 3.0)))))
#+END_SRC

How many times is the procedure t-identity applied when (sine 12.15) is evaluated?

#+BEGIN_SRC scheme
(sine 12.15)
#+END_SRC

#+RESULTS:
-.39980345741334

We know that \theta(t-identity) is ~n/3. Therefore, we need to know how many calls it would take to go from 12.15 to 0.1. 

#+BEGIN_SRC scheme
(/ 12.15 3)
(/ 4.05 3)
(/ 1.3499999 3)
(/ .44999999 3)
(/ .14999999 3)
#+END_SRC

#+RESULTS:
4.9999996666666664e-2
.14999999666666666
.4499999666666667
1.3499999999999999
4.05

It would take 5 calls.

What is the order of growth in space and number of steps (as a function of a) used by the process generated by the sine procedure when (since a) is evaluated? 

We saw previously that it took 5 steps.
Essentially 5 = (/ (/ (/ (/ (/ 12.15 3) 3) 3) 3) 3)

We could write our algorithm with some simple algebra: 

n / 3^x = 0.1
1 / 3^x = 0.1 / n
3^x = n / 0.1
x = log3(n / 0.1)
x = (log(n) - log(0.1)) / log(3)

Then, since our iterations are an integer, we could take the ceiling

#+BEGIN_SRC scheme
(define (oog input-num small-enough log-base)
  (ceiling (/ (- (log input-num) (log small-enough))
     (log log-base))))

(oog 12.15 0.1 3)
#+END_SRC

#+RESULTS:
5.

Thus, our expression grows the same in time and space, and has a big O value of (log a)

** 1.2.4 | Exponentiation

Consider the problem of computing the exponential of a given number. We would like a procedure which takes as arguments a base *b* and a positive integer exponent *n* and computes *b^n*. 

As easy way to do this is recursively

#+BEGIN_SRC scheme
(define (expt b n)
  (if (= n 0)
      1
      (* b (expt b (- n 1)))))

(expt 2 4)
#+END_SRC

#+RESULTS:
16

This is a linear recursive process which requires theta(n) steps and theta(n) space.

Here is an equivalent linear iteration

#+BEGIN_SRC scheme
(define (expt-iter b n)
  (define (iter counter product)
    (if (= counter 0)
        product
        (iter (- counter 1)
              (* b product))))
  (iter n 1))

(expt-iter 2 4)
#+END_SRC

#+RESULTS:
16

This version requires theta(n) steps and theta(1) space.

We can compute exponentials in even fewer steps with a squaring rule

For instance, rather than computing b^8 as b(b(b(...(b)))), we could compute it with 3 multiplications

b^2 = b * b
b^4 = b^2 * b^2
b^8 = b^4 * b^4

We could use the rule

b^n = (b^n/2)^2 if n is even
b^n = b * (b^n-1) if n is odd
 
#+BEGIN_SRC scheme
(define (even? n)
  (= (remainder n 2) 0))

(define (fast-expt b n)
  (cond ((= n 0) 1)
        ((even? n)
         (square (fast-expt b (/ n 2))))
        (else (* b (fast-expt b (- n 1))))))
#+END_SRC

#+RESULTS:
fast-expt
fast-expt
fast-expt
#[constant 40 #x2]


#+BEGIN_SRC scheme
(even? 4)
#+END_SRC

#+RESULTS:
#t
#f

#+BEGIN_SRC scheme
(fast-expt 2 4)
#+END_SRC

#+RESULTS:
16

- Exercise 1.16

Using the observation that (b^n/2)^2 = (b^2)^(n/2), keep, along with the exponent *n* and base *b*, an additional state variable *a*, and define the state transformation in such a way that the product ab^n is unchanged from state to state. At the beginning of the process *a* is taken to be 1 and the answer is given by the value of *a* at the end of the process.

#+DOWNLOADED: /tmp/screenshot.png @ 2020-02-08 10:18:02
[[file:1.2 | Procedures and the Processes They Generate/screenshot_2020-02-08_10-18-02.png]]

#+BEGIN_SRC scheme
(define (exp-iter b n)
  (define (iter b n a)
    (cond ((= n 0) a)
          ((even? n) (iter (square b) (/ n 2) a))
          (else (iter b (- n 1) (* b a)))))
  (iter b n 1))
#+END_SRC

#+RESULTS:
exp-iter

#+BEGIN_SRC scheme
(exp-iter 1 5)
#+END_SRC

#+RESULTS:
1
0
1024
32
16
8

- 1.17 

#+BEGIN_SRC scheme
(define (times a b)
  (if (= b 0)
      0
      (+ a (times a (- b 1)))))

(define (double x)
  (+ x x))

(define (halve x)
  (/ x 2))

(define (fast-mult a b)
  (cond ((= b 1) a)
        ((even? b) (double (fast-mult a (halve b))))
        (else (+ a (fast-mult a (- b 1))))))
#+END_SRC

#+BEGIN_SRC scheme
(fast-mult 100 100)
#+END_SRC

#+RESULTS:
10000

- Exercise 1.18

#+BEGIN_SRC scheme
(define (fast-mult-iter a b)
  (define (iter b c)
    (cond ((= b 1) (+ a c))
          ((even? b) (iter (halve b) (double c)))
          (else (iter (- b 1) (+ c a)))))
  (iter b 0))
#+END_SRC

#+BEGIN_SRC scheme
(fast-mult-iter 2 7)
#+END_SRC

#+BEGIN_SRC scheme
(define (fast-mult-iter a b)
  (define (iter b c)
    (cond ((= b 1) (+ a c))
          ((even? b) (iter (halve b) (double c)))
          (else (iter (- b 1) (+ c a)))))
  
  (cond ((even? b)
         (iter b 1))
        (else (iter b 0))))
#+END_SRC

#+RESULTS:
fast-mult-iter
fast-mult-iter

#+BEGIN_SRC scheme
(fast-mult-iter 2)
#+END_SRC

#+RESULTS:
14
10
18
18

This works for values of b up to 10, then it breaks.

After much trepidation and watching this:

https://www.youtube.com/watch?v=HJ_PP5rqLg0


#+BEGIN_SRC scheme
(define (halve x)
  (floor (/ x 2)))

(define (russian-mult a b)
  (define (iter a b c)
    (cond ((= b 0) c)
          ((even? b) (iter (double a) (halve b) c))
          (else (iter (double a) (halve b) (+ a c)))))
  (iter a b 0))
#+END_SRC

#+RESULTS:
russian-mult

#+BEGIN_SRC scheme
(halve 4)
#+END_SRC

#+BEGIN_SRC scheme
(russian-mult 22 100)
#+END_SRC

#+RESULTS:
2200
200
20
12
10

- Exercise 1.19

Recall the transformation of the state variables a and b in the fib-iter process of section 1.2.2: 

a <- a + b
b <- a 

Let this be called T, and observe that applying T over and over again n times, starting with a = 1 and b = 0 produces the pair Fib(n + 1) and Fib(n)


#+BEGIN_SRC scheme
(define (fib n)
  (define (iter a b n)
    (cond ((= n 0) b)
          (else (iter (+ a b) a (- n 1)))))
  (iter 1 0 n))
#+END_SRC

#+BEGIN_SRC scheme
(fib 10)
#+END_SRC

In other words, the Fibonacci numbers are produced by applying T^n, the nth power of the transformation T, starting with the pair (1, 0). 

Now consider T to be a special case of p = 0 and q = 1 in a family of transformations T_pq where T_pq transforms the pair (a, b) according to

a <- bq + aq + ap
b <- bp + aq 

Show that if we apply such a transformation T_pq twice, the effect is the same as using a single transformation T_p'q' of the same form, and compute p' and q' in terms of p and q. 

This gives us an explicit way to square these transformations, and thus we can compute T^n using successive squaring as in the fast-exp procedure.

** 1.2.5 | Greatest Common Divisors

The GCD of two integers a and b is defined to be the largest integer that divides both a and b with no remainder. 

The idea of *Euclid's Algorithm* is based on the observation that, if r is the remainder when a is divided by b, then the common divisors of a and b are precisely the same as the common divisors of b and r. 

Thus, we can use the equation GCD(a, b) = GCD(b, r) to successively reduce the problem of computing a GCD to the problem of computing the GCD of smaller and smaller pairs of integers. 

For example: 

GCD(206, 40) = GCD(40, 6)
             = GCD(6, 4)
             = GCD(4, 2)
             = GCD(2, 0)
             = 2

It is possible to show that starting with any two positive integers and performing repeated reductions will always eventually produce a pair where the second number is 0 and the first number is the GCD. 

#+BEGIN_SRC scheme
(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
#+END_SRC

#+RESULTS:
gcd

#+BEGIN_SRC scheme
(gcd 206 40)
#+END_SRC

#+RESULTS:
2

The fact that the number of steps required by Euclid's Algorithm has logarithmic growth bears an interesting relation to the Fibonacci numbers:

*Lame's Theorem*

If Euclid's algorithm requires k steps to compute the GCD of some pair, then the smaller number in the pair must be greater than or equal to the kth Fibonacci number

#+BEGIN_SRC scheme
(fib 4)
#+END_SRC

We can use Lame's theorem to get an order of growth estimate for Euclid's algorithm. 
