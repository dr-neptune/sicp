* 1.2 | Procedures and the Processes They Generate
:PROPERTIES:
:header-args: :session scheme :results value
:END:

A procedure is a pattern for the local evolution of a computational process. It specifies how each stage of the process is built upon the previous stage. We would like to be able to make statements about the overall, or global, behavior of a process whose local evolution has been specified by a procedure. 

** 1.2.1 | Linear Recursion and Iteration

#+BEGIN_SRC scheme
(define (factorial n)
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))

(factorial 5)
#+END_SRC

#+RESULTS:
120
120
3628800
1
2

This is the linear recursive method for computing factorials


#+DOWNLOADED: /tmp/screenshot.png @ 2020-02-02 10:52:25
[[file:1.2 | Procedures and the Processes They Generate/screenshot_2020-02-02_10-52-25.png]]

The substitution model reveals a shape of expansion followed by contraction. The expansion occurs as the process builds up a chain of deferred operations. The contraction occurs as the operations are actually performed. 

This type of process, characterized by a chain of deferred operations, is called a recursive process. 

#+BEGIN_SRC scheme
(define (factorial n)
  (define (iter product counter)
    (if (> counter n)
        product
        (iter (* product counter) 
              (+ counter 1))))

  (iter 1 1))

(factorial 5)
#+END_SRC

#+RESULTS:
120
1
1
720
factorial

This is the linear iterative process for computing a factorial.

#+DOWNLOADED: /tmp/screenshot.png @ 2020-02-02 10:56:28
[[file:1.2 | Procedures and the Processes They Generate/screenshot_2020-02-02_10-56-28.png]]

In contrast to the above, this method does not grow and shrink. At each step we keep track of, for any n, the current values of product, counter, and max-count. This is an iterative process. 

In general, an iterative process is one whose state can be summarized by a fixed number of state variables, together with a fixed rule that describes how the state variables should be updated as the process moves from state to state and an optional end test that specifies conditions under which the process should terminate. 

In contrasting iteration and recursion, we must not confuse the notion of a recursive process with the notion of a recursive procedure. 

When we describe a procedure as recursive, we are referrring to the syntactic fact that the procedure definition refers (either directly or indirectly) to the procedure itself.

When we describe a process as following a pattern that is linearly recursive we are speaking about how the process evolves, not about the syntax with how it is written. 

This is confusing because the implementation of most imperative languages are designed in such a way that the interpretation of any recursive procedure consumes an amount of memory that grows with the number of procedure calls. As a consequence, these languages resort to special purpose looping constructs such as do, repeat, until, for, and while. 

In contrast scheme executes an iterative process in constant space, even if the iterative process is described by a recursive procedure. An implementation with this property is called tail recursive. 

*** Exercise 1.9 

#+BEGIN_SRC scheme
(define (+ a b)
  (if (= a 0)
      b
      (inc (+ (dec a) b))))
#+END_SRC

#+BEGIN_SRC scheme
(+ 4 5)
(inc (+ 3 5))
(inc 8)
(9)
#+END_SRC

#+BEGIN_SRC scheme
(+ 4 5)
(inc (+ (dec 4) 5))
(inc (+ 3 5))
(inc (inc (+ (dec 3) 5)))
(inc (inc (+ 2 5)))
(inc (inc (inc (+ (dec 2) 5))))
(inc (inc (inc (+ 1 5))))
(inc (inc (inc (inc (+ (dec 1) 5)))))
(inc (inc (inc (inc (+ 0 5)))))
(inc (inc (inc (inc 5))))
(inc (inc (inc 6)))
(inc (inc 7))
(inc 8)
9
#+END_SRC

This is a recursive process

#+BEGIN_SRC scheme
(define (+ a b)
  (if (= a 0)
      b
      (+ (dec a) (inc b))))
#+END_SRC

#+BEGIN_SRC scheme
(+ 4 5)
(+ 3 6)
(+ 2 7)
(+ 1 8)
(+ 0 9)
9
#+END_SRC

This is an iterative process

*** Exercise 1.10 

#+BEGIN_SRC scheme
(define (ackermann x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (Ackermann (- x 1)
                         (Ackermann x (- y 1))))))
#+END_SRC

#+RESULTS:
ackermann
ackermann

#+BEGIN_SRC scheme
(ackermann 1 10)
#+END_SRC

#+RESULTS:
1024

#+BEGIN_SRC scheme
(ackermann 2 4)
#+END_SRC

#+RESULTS:
65536

#+BEGIN_SRC scheme
(ackermann 3 3)
#+END_SRC

#+RESULTS:
65536

#+BEGIN_SRC scheme
(define (f n) (Ackermann 0 n))
(define (g n) (Ackermann 1 n))
(define (h n) (Ackermann 2 n))
(define (k n) (* 5 n n))
#+END_SRC


- (f n) : 2n

#+BEGIN_SRC scheme
A (0, n)
2n
#+END_SRC

#+BEGIN_SRC scheme
(ackermann 0, 4)
#+END_SRC

- (g n) : 

#+BEGIN_SRC scheme
A (1, n)
A (0, A (1, n-1))
A (0, A (0, A (1, n-2)))
A (0, A (0, A (0, A (1, n - 3))))
...
until y = 1, in which case we have 
2 ( 2 ( 2 ( ... ( 2)))), or 2^n
#+END_SRC

#+BEGIN_SRC scheme
(ackermann 1 4)
#+END_SRC

#+RESULTS:
16

- (h n) : 

#+BEGIN_SRC scheme
A (2, n)
A (1, A (2, n - 1))
A (1, A (1, A (2, n - 2)))
...
A (1, A (1, ...n..., 2))
(2^n (2^n (2^n, ...n..., 2^n)))
(2^n)^n

We know A (1, n) ~ 2^n, and we know this will terminate when y = 1 with a 2. Therefore we will get one full set of A (1, ...) that consists of n terms per x, and each of these terms will become 2^n. Thus we get (2^n)^n
#+END_SRC

#+BEGIN_SRC scheme
(ackermann 2 4)
#+END_SRC

#+RESULTS:
65536

** 1.2.2 | Tree Recursion

Another common pattern of computation is called tree recursion. 

#+BEGIN_SRC scheme
(define (fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))

(fib 5)
#+END_SRC

#+RESULTS:
: 5
5
3
2
1
1
0
fib


#+DOWNLOADED: /tmp/screenshot.png @ 2020-02-03 20:37:41
[[file:1.2 | Procedures and the Processes They Generate/screenshot_2020-02-03_20-37-41.png]]

This procedure is instructive, but hopelessly inefficient. Almost half the computation is repeated twice. 

The value of Fib(n) grows exponentially with n. More precisely, Fib(n) is the closest integer to $\phi^n / \sqrt{5}$, where 

$\phi = \frac{1 + \sqrt{5}}{2} ~ 1.618$

is the golden ratio, which satisfies the equation 

$\phi^2 = \phi + 1$

Thus the process uses a number of steps that grow exponentially with the input. On the other hand, the space required grows only linearly with the input, because we need keep track of only which nodes are above us in the tree at any point in the computation. 

In general, the number of steps required by a tree-recursive process will be proportional to the number of nodes in the tree, while the space required will be proportional to the maximum depth of the tree.

We can also formulate an iterative process for computing the Fibonacci numbers, in which we use a pair of integers a and b initialized to Fib(1) and Fib(0), to repeatedly apply the transformations

$a <- a + b$
$b <- a$

#+BEGIN_SRC scheme
(define (fib n)
  (define (iter a b count)
    (if (= count 0)
        b
        (iter (+ a b) a (- count 1))))
  (iter 1 0 n))

(fib 50)
#+END_SRC

#+RESULTS:
12586269025
21
13
8
5
3
2
1
1
0
fib

This method is a linear iteration. The difference in number of steps required by the two methods is enormous, even for small inputs.

We should not conclude that tree-recursive processes are useless. When we consider processes that operate on hierarchically structured data rather than numbers, we will find that tree recursion is a natural and powerful tool.

Notice how much easier and natural the first approach was in contrast to the second approach. The first is essentially a recasting of the definition into lisp, whereas the second needed to place it in the context of using 3 state variables.

*Example: Counting Change*

How many different ways can we make change of $1.00, given half-dollars, quarters, dimes, nickels, and pennies? 

Suppose we think of the types of coins available as arranged in some order. Then the following relation holds:

The number of ways to change amount a using n kinds of coins equals

- the number of ways to change amount a using all but the first kind of coin, plus
- the number of ways to change amount a - d, using all n kinds of coins where d is the denomination of the first coin 

Observe that the ways to make change can be divided into two groups: those that do not use any of the first kind of coin and those that do. Therefore, the total number of ways to make change for some amount is equal to the number of ways to make change for the amount without using any of the first kind of coin, plus the number of ways to make change assuming that we do use the first kind of coin. But the latter number is equal to the number of ways to make change for the amount that remains after using a coin of the first kind. 

Thus we can recursively reduce the problem of changing a given amount to the problem of changing smaller amounts using fewer kinds of coins. 

- If a is exactly 0, we should count that as 1 way to make change
- If a is less than 0, we should count that as 0 ways to make change.
- If n is 0, we should count that as 0 ways to make change

#+BEGIN_SRC scheme
(define (count-change amount)
  (define (first-denomination kinds-of-coins)
    (cond ((= kinds-of-coins 1) 1)
          ((= kinds-of-coins 2) 5)
          ((= kinds-of-coins 3) 10)
          ((= kinds-of-coins 4) 25)
          ((= kinds-of-coins 5) 50)))
  
  (define (cc amount kinds-of-coins)
    (cond ((= amount 0) 1)
          ((or (< amount 0) (= kinds-of-coins 0)) 0)
          (else (+ (cc amount (- kinds-of-coins 1))
                   (cc (- amount 
                          (first-denomination
                           kinds-of-coins))
                       kinds-of-coins)))))
  (cc amount 5))
#+END_SRC

#+RESULTS:
count-change

The first-denomination procedure takes as input the number of kinds of coins available and returns the denomination of the first kind. 

#+BEGIN_SRC scheme
(count-change 100)
#+END_SRC

#+RESULTS:
292

This procedure generates a tree-recursive process with redundancies similar to our first implementation of fib. 

generate all the ways to get our amount with one coin type
this is 5 ways

generate pennies - first denom (nickels). Then we have 95 pennies, 1 nickel, 90, 2 nickels, etc for another 20 ways. 

then generate pennies - second denom (dimes). Then we have 90 pennies, 1 dime, 85 pennies, 1 nickel, 1 dime, 80 pennies, 2 nickels, 1 dime, 80 pennies, 2 dimes

*** Exercise 1.11

function is defined by 


#+DOWNLOADED: /tmp/screenshot.png @ 2020-02-03 21:22:21
[[file:1.2 | Procedures and the Processes They Generate/screenshot_2020-02-03_21-22-21.png]] 

#+BEGIN_SRC scheme
(define (fun n)
  (cond ((< n 3) n)
        (else (+ (fun (- n 1))
                 (* (fun (- n 2)) 2)
                 (* (fun (- n 3)) 3)))))

(fun 8)
#+END_SRC

#+RESULTS:
335

#+BEGIN_SRC scheme
(define (fun2 n)
  (define (iter a b c count)
    (cond ((< count 0) count)
          ((= count 0) a)
          ((= count 1) b)
          ((= count 2) c)
          (else (iter b c (+ c (* 2 b) (* 3 a)) (- count 1)))))
  (iter 0 1 2 n))
#+END_SRC

#+RESULTS:
fun2

#+BEGIN_SRC scheme
(fun2 8)
#+END_SRC

Fix this ^^^ 

*** Exercise 1.12 

Generate nth row and kth column of pascal's triangle

#+BEGIN_SRC scheme
(define (pascal n k)
  (cond ((= n 0) 1)
        ((= k 0) 1)
        ((/ (factorial n)
            (* (factorial k)
               (factorial (- n k)))))))
#+END_SRC

#+RESULTS:
pascal

#+BEGIN_SRC scheme
(pascal 6 3)
#+END_SRC

Generate sum of entire nth row to the kth column

*** Exercise 1.13 
** 1.2.3 | Orders of Growth
*** Exercise 1.15

The sine of an angle (specified in radians) can be computed by making use of the approximation sin x ~ x if x is sufficiently small, and the trigonometric identity 

$\sin{x} = 3\sin{\frac{x}{3}} - 4\sin{\frac{x}{3}}^3$

to reduce the size of the argument of sin. For the purposes of this exercise, an angle is considered sufficiently small if its magnitude is not greater than 0.1 radians. 

#+BEGIN_SRC scheme
(define (abs x)
  (cond ((< x 0) (- x))
        (else x)))

(define (cube x) (* x x x))

(define (t-identity x)
  (- (* 3 x) (* 4 (cube x))))

(define (sine angle)
  (if (not (> (abs angle) 0.1))
      angle
      (t-identity (sine (/ angle 3.0)))))
#+END_SRC

How many times is the procedure t-identity applied when (sine 12.15) is evaluated?

#+BEGIN_SRC scheme
(sine 12.15)
#+END_SRC

#+RESULTS:
-.39980345741334

We know that \theta(t-identity) is ~n/3. Therefore, we need to know how many calls it would take to go from 12.15 to 0.1. 

#+BEGIN_SRC scheme
(/ 12.15 3)
(/ 4.05 3)
(/ 1.3499999 3)
(/ .44999999 3)
(/ .14999999 3)
#+END_SRC

#+RESULTS:
4.9999996666666664e-2
.14999999666666666
.4499999666666667
1.3499999999999999
4.05

It would take 5 calls.

What is the order of growth in space and number of steps (as a function of a) used by the process generated by the sine procedure when (since a) is evaluated? 

We saw previously that it took 5 steps.
Essentially 5 = (/ (/ (/ (/ (/ 12.15 3) 3) 3) 3) 3)

We could write our algorithm with some simple algebra: 

n / 3^x = 0.1
1 / 3^x = 0.1 / n
3^x = n / 0.1
x = log3(n / 0.1)
x = (log(n) - log(0.1)) / log(3)

Then, since our iterations are an integer, we could take the ceiling

#+BEGIN_SRC scheme
(define (oog input-num small-enough log-base)
  (ceiling (/ (- (log input-num) (log small-enough))
     (log log-base))))

(oog 12.15 0.1 3)
#+END_SRC

#+RESULTS:
5.

Thus, our expression grows the same in time and space, and has a big O value of (log a)

** 1.2.4 | Exponentiation

Consider the problem of computing the exponential of a given number. We would like a procedure which takes as arguments a base *b* and a positive integer exponent *n* and computes *b^n*. 

As easy way to do this is recursively

#+BEGIN_SRC scheme
(define (expt b n)
  (if (= n 0)
      1
      (* b (expt b (- n 1)))))

(expt 2 4)
#+END_SRC

#+RESULTS:
16

This is a linear recursive process which requires theta(n) steps and theta(n) space.

Here is an equivalent linear iteration

#+BEGIN_SRC scheme
(define (expt-iter b n)
  (define (iter counter product)
    (if (= counter 0)
        product
        (iter (- counter 1)
              (* b product))))
  (iter n 1))

(expt-iter 2 4)
#+END_SRC

#+RESULTS:
16

This version requires theta(n) steps and theta(1) space.

We can compute exponentials in even fewer steps with a squaring rule

For instance, rather than computing b^8 as b(b(b(...(b)))), we could compute it with 3 multiplications

b^2 = b * b
b^4 = b^2 * b^2
b^8 = b^4 * b^4

We could use the rule

b^n = (b^n/2)^2 if n is even
b^n = b * (b^n-1) if n is odd
 
#+BEGIN_SRC scheme
(define (even? n)
  (= (remainder n 2) 0))

(define (fast-expt b n)
  (cond ((= n 0) 1)
        ((even? n)
         (square (fast-expt b (/ n 2))))
        (else (* b (fast-expt b (- n 1))))))
#+END_SRC

#+RESULTS:
: #[constant 40 #x2]
fast-expt
fast-expt
fast-expt
#[constant 40 #x2]


#+BEGIN_SRC scheme
(even? 4)
#+END_SRC

#+RESULTS:
#t
#f

#+BEGIN_SRC scheme
(fast-expt 2 4)
#+END_SRC

#+RESULTS:
16

*** Exercise 1.16

Using the observation that (b^n/2)^2 = (b^2)^(n/2), keep, along with the exponent *n* and base *b*, an additional state variable *a*, and define the state transformation in such a way that the product ab^n is unchanged from state to state. At the beginning of the process *a* is taken to be 1 and the answer is given by the value of *a* at the end of the process.

#+DOWNLOADED: /tmp/screenshot.png @ 2020-02-08 10:18:02
[[file:1.2 | Procedures and the Processes They Generate/screenshot_2020-02-08_10-18-02.png]]

#+BEGIN_SRC scheme
(define (exp-iter b n)
  (define (iter b n a)
    (cond ((= n 0) a)
          ((even? n) (iter (square b) (/ n 2) a))
          (else (iter b (- n 1) (* b a)))))
  (iter b n 1))
#+END_SRC

#+RESULTS:
exp-iter

#+BEGIN_SRC scheme
(exp-iter 1 5)
#+END_SRC

#+RESULTS:
1
0
1024
32
16
8

*** 1.17 

#+BEGIN_SRC scheme
(define (times a b)
  (if (= b 0)
      0
      (+ a (times a (- b 1)))))

(define (double x)
  (+ x x))

(define (halve x)
  (/ x 2))

(define (fast-mult a b)
  (cond ((= b 1) a)
        ((even? b) (double (fast-mult a (halve b))))
        (else (+ a (fast-mult a (- b 1))))))
#+END_SRC

#+BEGIN_SRC scheme
(fast-mult 100 100)
#+END_SRC

#+RESULTS:
10000

*** Exercise 1.18

#+BEGIN_SRC scheme
(define (fast-mult-iter a b)
  (define (iter b c)
    (cond ((= b 1) (+ a c))
          ((even? b) (iter (halve b) (double c)))
          (else (iter (- b 1) (+ c a)))))
  (iter b 0))
#+END_SRC

#+BEGIN_SRC scheme
(fast-mult-iter 2 7)
#+END_SRC

#+BEGIN_SRC scheme
(define (fast-mult-iter a b)
  (define (iter b c)
    (cond ((= b 1) (+ a c))
          ((even? b) (iter (halve b) (double c)))
          (else (iter (- b 1) (+ c a)))))
  
  (cond ((even? b)
         (iter b 1))
        (else (iter b 0))))
#+END_SRC

#+RESULTS:
fast-mult-iter
fast-mult-iter

#+BEGIN_SRC scheme
(fast-mult-iter 2)
#+END_SRC

#+RESULTS:
14
10
18
18

This works for values of b up to 10, then it breaks.

After much trepidation and watching this:

https://www.youtube.com/watch?v=HJ_PP5rqLg0


#+BEGIN_SRC scheme
(define (halve x)
  (floor (/ x 2)))

(define (russian-mult a b)
  (define (iter a b c)
    (cond ((= b 0) c)
          ((even? b) (iter (double a) (halve b) c))
          (else (iter (double a) (halve b) (+ a c)))))
  (iter a b 0))
#+END_SRC

#+RESULTS:
russian-mult

#+BEGIN_SRC scheme
(halve 4)
#+END_SRC

#+BEGIN_SRC scheme
(russian-mult 22 100)
#+END_SRC

#+RESULTS:
2200
200
20
12
10

*** Exercise 1.19

Recall the transformation of the state variables a and b in the fib-iter process of section 1.2.2: 

a <- a + b
b <- a 

Let this be called T, and observe that applying T over and over again n times, starting with a = 1 and b = 0 produces the pair Fib(n + 1) and Fib(n)


#+BEGIN_SRC scheme
(define (fib n)
  (define (iter a b n)
    (cond ((= n 0) b)
          (else (iter (+ a b) a (- n 1)))))
  (iter 1 0 n))
#+END_SRC

#+RESULTS:
: fib
fib

#+BEGIN_SRC scheme
(fib 10)
#+END_SRC

#+RESULTS:
: 55

In other words, the Fibonacci numbers are produced by applying T^n, the nth power of the transformation T, starting with the pair (1, 0). 

Now consider T to be a special case of p = 0 and q = 1 in a family of transformations T_pq where T_pq transforms the pair (a, b) according to

a <- bq + aq + ap
b <- bp + aq 

Show that if we apply such a transformation T_pq twice, the effect is the same as using a single transformation T_p'q' of the same form, and compute p' and q' in terms of p and q. 

This gives us an explicit way to square these transformations, and thus we can compute T^n using successive squaring as in the fast-exp procedure.

** 1.2.5 | Greatest Common Divisors

The GCD of two integers a and b is defined to be the largest integer that divides both a and b with no remainder. 

The idea of *Euclid's Algorithm* is based on the observation that, if r is the remainder when a is divided by b, then the common divisors of a and b are precisely the same as the common divisors of b and r. 

Thus, we can use the equation GCD(a, b) = GCD(b, r) to successively reduce the problem of computing a GCD to the problem of computing the GCD of smaller and smaller pairs of integers. 

For example: 

GCD(206, 40) = GCD(40, 6)
             = GCD(6, 4)
             = GCD(4, 2)
             = GCD(2, 0)
             = 2

It is possible to show that starting with any two positive integers and performing repeated reductions will always eventually produce a pair where the second number is 0 and the first number is the GCD. 

#+BEGIN_SRC scheme
(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
#+END_SRC

#+RESULTS:
: gcd
gcd

#+BEGIN_SRC scheme
(gcd 206 40)
#+END_SRC

#+RESULTS:
: 2
2

The fact that the number of steps required by Euclid's Algorithm has logarithmic growth bears an interesting relation to the Fibonacci numbers:

*Lame's Theorem*

If Euclid's algorithm requires k steps to compute the GCD of some pair, then the smaller number in the pair must be greater than or equal to the kth Fibonacci number

#+BEGIN_SRC scheme
(fib 4)
#+END_SRC

#+RESULTS:
: 3

We can use Lame's theorem to get an order of growth estimate for Euclid's algorithm. If the process takes k steps, then we must have n >= Fib(k) ~ \phi^k / \sqrt(5). Therefore the number of steps k grows as the logarithm (to the base phi) of n. Hence the order of growth is theta(log n).


*** Exercise 1.20

The process that a procedure generates is of course dependent on the rules used by the interpreter. As an example, consider the iterative gcd procedure given above. Suppose we were to interpret this procedure using normal-order evaluation. 

#+BEGIN_SRC scheme
(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
#+END_SRC

#+RESULTS:
: gcd

Using the substitution method, illustrate the process generated in evaluating gcd(206 40) and indicate the remainder operations that are actually performed. How many remainder operations are actually performed in the normal order evaluation? 

#+BEGIN_SRC scheme
(gcd 206 40)
1 (gcd 40 (remainder 206 40))

2 (gcd (remainder 206 40) (remainder 40 (remainder 206 40))

3 (gcd (remainder 40 (remainder 206 40))
       (remainder (remainder 206 40) (remainder 40 (remainder 206 40))))

4 (gcd (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))
       (remainder (remainder 40 (remainder 206 40)) 
                  (remainder (remainder 206 40) 
                             (remainder 40 (remainder 206 40)))))

5 (gcd (remainder (remainder 40 (remainder 206 40)) 
                  (remainder (remainder 206 40) 
                             (remainder 40 (remainder 206 40))))
       (remainder (remainder (remainder 206 40) 
                             (remainder 40 (remainder 206 40)))
                  (remainder (remainder 40 (remainder 206 40)) 
                             (remainder (remainder 206 40) 
                                        (remainder 40 
                                                   (remainder 206 40))))))
#+END_SRC

there are 19 invocations to remainder, but the first invocation will be (2 0), so it will be caught by our if statement and will not need to be computed, so we have 18 invocations

For applicative order

#+BEGIN_SRC scheme
(gcd 206 40)
(gcd 40 (remainder 206 40))
(gcd 40 6)
(gcd 6 (remainder 40 6))
(gcd 6 4)
(gcd 4 (remainder 6 4))
(gcd 4 2)
(gcd 2 (remainder 4 2))
(gcd 2 0)
2
#+END_SRC

#+RESULTS:
: 2

For the applicative order, we will call remainder 4 times

** 1.2.6 | Testing for Primality

This section describes two methods for checking the primality of an integer n, one with growth theta(sqrt(n)) and a probabilistic algorithm with growth theta(log n). 

*** Searching for Divisors

The following program finds the smallest integral divisor (greater than 1) of a given number n. It does this by testing n for divisibility by successive integers starting with 2

#+BEGIN_SRC scheme
(define (square x)
  (* x x))

(define (smallest-divisor n)
  (find-divisor n 2))

(define (find-divisor n test-divisor)
  (cond ((> (square test-divisor) n) n)
        ((divides? test-divisor n) test-divisor)
        (else (find-divisor n (+ test-divisor 1)))))

(define (divides? a b)
  (= (remainder a b) 0))

(define (prime? n)
  (= n (smallest-divisor n)))
#+END_SRC

#+RESULTS:
: #[constant 40 #x2]

The end test for find-divisor is based on the fact that if n is not prime, it must have a divisor less than or equal to sqrt(n). This means that the algorithm need only test divisors between 1 and sqrt(n). Consequently, the number of steps required to identify n as prime will have order of growth theta(sqrt(n))

*** The Fermat Test

*Fermat's Little Theorem*

If n is a prime number and a is any positive integer less than n, then a raised to the nth power is congruent to a mod n

Two numbers are said to be congruent modulo n if they both have the same remainder when divided by n. The remainder of a number a when divided by n is also referred to as the remainder of a mod n. 

If n is not prime, then in general most of the numbers a < n will not satisfy the above relation. This leads to the following algorithm for testing primality:

- Given a number n
- pick a number a < n
- compute the remainder of a^n mod n
- if result != a, then n is not prime
- if result == a, then chances are good n is prime
- pick another random number b and test it with the same method
- if b also satisfies the equation, we increase our confidence
- as we test more numbers, c, d, e, f we increase our confidence

This is known as the Fermat test


To implement this, we need a procedure that computes the exponential of a number modulo another number

#+BEGIN_SRC scheme
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (square (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder 
          (* base (expmod base (- exp 1) m))
          m))))
#+END_SRC

#+RESULTS:
: expmod
expmod

This is very similar to the fast-expt procedure from before in that it uses successive squaring so that the number of steps grows logarithmically with the exponent.

The Fermat test is performed by choosing at random a number a between 1 and n-1 inclusive and checking whether the remainder mod n of the nth power of a is equal to a. The random number a is chosen using the scheme primitive random. random returns an integer between 1 and its given parameter.

#+BEGIN_SRC scheme
(define (fermat-test n)
  (define (try-it a)
    (= (expmod a n n) a))
  (try-it (+ 1 (random (- n 1)))))

(fermat-test 6)
#+END_SRC

#+RESULTS:
: #t

The following procedure runs the test a given number of times, as specified by a parameter. Its value is true if the test succeeds every time, false otherwise

#+BEGIN_SRC scheme
(define (fast-prime? n times)
  (cond ((= times 0) true)
        ((fermat-test n) (fast-prime? n (- times 1)))
        (else false)))
#+END_SRC

#+RESULTS:
: fast-prime?
fast-prime?

Let's try the second Cullen prime (of the form n*2^n + 1)

#+BEGIN_SRC scheme
(fast-prime? 393050634124102232869567034555427371542904833 5)
#+END_SRC

#+RESULTS:
: #t


*** Exercise 1.21 

Use the smallest-divisor procedure to find the smallest-divisor of each of the following numbers: 

#+BEGIN_SRC scheme
(smallest-divisor 1)
#+END_SRC

#+RESULTS:
: 1
1999999
199999
19999
1999
199
19
1

*** Exercise 1.22 

Most lisp implementatoins include a primitive called runtime that returns an integer that specifies the amount of time the system has been running.

The following procedure, when called with an integer n, prints n and checks to see if n is prime. If n is prime, the procedure prints three asterisks followed by the amount of time used in performing the test

#+BEGIN_SRC scheme
(define (timed-prime-test n)
  (newline)
  (display n)
  (start-prime-test n (runtime)))

(define (start-prime-test n start-time)
  (if (prime? n)
      (report-prime (- (runtime) start-time))))

(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))
#+END_SRC

#+RESULTS:
: #[constant 40 #x2]

Using this procedure, write a procedure search-for-primes that checks the primality of consecutive odd integers in a specified range. Use your procedures to find the three smallest primes larger than 1000; 10000; 100000; 1000000

#+BEGIN_SRC scheme
(define (search-for-primes start end)
  (define (iter start end count)
    (cond ((or (= start end)
               (= count 0)) (timed-prime-test start))
          ((fast-prime? start 5)
           (display start)
           (newline)
           (iter (+ start 2) end (- count 1)))
          (else (iter (+ start 2) end count))))
  (cond ((< end start) 0)
        ((even? start)
         (iter (+ start 1) end 3))
        (else (iter start end 3))))
#+END_SRC

#+RESULTS:
: search-for-primes

#+BEGIN_SRC scheme :results output
(search-for-primes 10000 99999)
#+END_SRC

---------------------------------------------------------------

For 12 digits (search-for-primes 100000000000 999999999999) we get

100000000003
100000000019
100000000057

100000000059 *** .2400000000000002

---------------------------------------------------------------

For 13 digits (search-for-primes 10000000000 99999999999) we get

1000000000039
1000000000061
1000000000063

1000000000065 *** .6899999999999995

---------------------------------------------------------------

For 14 digits (search-for-primes 100000000000 999999999999) we get

10000000000037
10000000000051
10000000000099

10000000000101 *** 2.1999999999999993

---------------------------------------------------------------

Our order of growth per digit is 

12 -> 13 is a *2.875x* increase in time 
13 -> 14 is a *3.187x* increase in time
12 -> 14 is a *9.167x* increase in time

We expect that each jump should take around sqrt(10) ~ 3.16 times as long.

#+BEGIN_SRC scheme
(square 3.16)
#+END_SRC

#+RESULTS:
: 9.985600000000002
9.985600000000002

The jump for each is around 3, and the jump from 12 to 14 is around 3.16^2

*** Exercise 1.23

#+BEGIN_SRC scheme
(define (timed-prime-test n)
  (newline)
  (display n)
  (start-prime-test n (runtime)))

(define (start-prime-test n start-time)
  (if (fast-prime? n 5)
      (report-prime (- (runtime) start-time))))

(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))
#+END_SRC

#+RESULTS:
: #[constant 40 #x2]
report-prime

*** Exercise 1.24 

See start-prime-test above. 

#+BEGIN_SRC scheme :results output
(search-for-primes 1000000 9999999)
#+END_SRC

#+RESULTS:
: 1000003
: 1000033
: 1000037
: 
: 1000039 *** 0.

*** Exercise 1.26 

*** Exercise 1.25 

Our previous expmod: 

#+BEGIN_SRC scheme
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (square (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder 
          (* base (expmod base (- exp 1) m))
          m))))
#+END_SRC

#+RESULTS:
: expmod

#+BEGIN_SRC scheme
(define (expmod2 base exp m)
  (remainder (fast-expt base exp) m))
#+END_SRC

#+RESULTS:
: expmod2

Let's look at the definition of fast-expt and write a square function that shows the intermediate steps.

#+BEGIN_SRC scheme
(define (square x)
  (display "square ")
  (display x)
  (newline)
  (* x x))

(define (fast-expt b n)
  (cond ((= n 0) 1)
        ((even? n)
         (square (fast-expt b (/ n 2))))
        (else (* b (fast-expt b (- n 1))))))
#+END_SRC

#+RESULTS:
: #[constant 40 #x2]

#+BEGIN_SRC scheme :results output
(expmod 8 50 3)
#+END_SRC

#+RESULTS:
: square 2
: square 2
: square 1
: square 1
: square 2

#+BEGIN_SRC scheme :results output
(expmod2 8 50 3)
#+END_SRC

#+RESULTS:
: square 8
: square 512
: square 262144
: square 68719476736
: square 37778931862957161709568

The difference is that the modulo operation is performed on each step in the original implementation of expmod. This allows the numbers to be kept relatively small through each step. In contrast, fast-expt squares at each step. 

expmod: remainder(square(result))
fast-expt: square(result)

So over the course of 3 steps we have 

expmod: (0 <= result <= m)
        (0 <= (0 <= result <= m) <= m)
        (0 <= (0 <= (0 <= result <= m) <= m) <= m)

fast-expt:
        (* 8 8 8)
        (* (* 8 8 8) 8 8)
        (* (* (* 8 8 8) 8 8) 8 8)

*** Exercise 1.26 

Original expmod

#+BEGIN_SRC scheme
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (square (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder 
          (* base (expmod base (- exp 1) m))
          m))))
#+END_SRC

Louis Reasoner's expmod:

#+BEGIN_SRC scheme
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder
          (* (expmod base (/ exp 2) m)
             (expmod base (/exp 2) m))
          m))
        (else (remainder
               (* base
                  (expmode base (- exp 1) m))
               m))))
#+END_SRC

Our original process runs in log2(n) time. When Louis rewrote the expmod code, for every call to expmod when exp is even his code generates two processes and for every call to an odd exp it returns another process. This has turned the linear recursion of expmod into a tree recursion. Tree recursion grows exponentially with n, as show in 1.2.2. 

Therefore, we have 2^(log2(n)), or theta(n)

*** Exercise 1.27 
